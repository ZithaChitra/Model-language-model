diff --git a/nd_lang/lab1/training/__pycache__/util.cpython-38.pyc b/nd_lang/lab1/training/__pycache__/util.cpython-38.pyc
index b35fad0..2651051 100644
Binary files a/nd_lang/lab1/training/__pycache__/util.cpython-38.pyc and b/nd_lang/lab1/training/__pycache__/util.cpython-38.pyc differ
diff --git a/nd_lang/lab1/training/run_experiment2.py b/nd_lang/lab1/training/run_experiment2.py
index f325132..aaf7d90 100644
--- a/nd_lang/lab1/training/run_experiment2.py
+++ b/nd_lang/lab1/training/run_experiment2.py
@@ -3,16 +3,12 @@ import importlib
 # from typing import Dict
 # import os
 import click
-# import mlflow
 
 # from lab1.training.util import train_model
 from lab1.training.util import save_net_artifact
 import wandb
 from wandb.keras import WandbCallback
-
-# from mlflow.models.signature import ModelSignature
-# from mlflow.types.schema import TensorSpec, Schema
-# import numpy as np
+import numpy as np
 
 
 DEFAULT_TRAIN_ARGS = {"batch_size":64, "epochs":16}
@@ -22,24 +18,23 @@ DEFAULT_TRAIN_ARGS = {"batch_size":64, "epochs":16}
 @click.argument("dataset", default="HousingData")
 @click.argument("network", default="mlp")
 @click.argument("model", default="Model")
-@click.argument("--name", default="nd_lang")
+@click.option("--proj-name", default="nd_lang")
 @click.option("--epoch", default=10)
 @click.option("--train-args", default=DEFAULT_TRAIN_ARGS)
-def run_experiment(dataset, network, model, name, epoch, train_args):
+def run_experiment(dataset, network, model, proj_name, epoch, train_args):
 
 	print(f"Running experiment with network '{network}' and dataset '{dataset}''")
 	datasets_module = importlib.import_module("lab1.language_model.datasets.house_pred")
 	dataset_class_ = getattr(datasets_module, dataset)
 	# dataset_args = experiment_config.get("dataset_args", {})
-	dataset = dataset_class_()
-	# dataset.load_or_generate_data()
+
 
 	models_module = importlib.import_module("lab1.language_model.models.base2")
 	model_class_ = getattr(models_module, model)
 
 	networks_module = importlib.import_module("lab1.language_model.networks.mlp")
 	network_fn = getattr(networks_module, network)
-	save_net_artifact(network_fn())
+	# save_net_artifact(project_name=proj_name, network=network_fn())
 	
 	# network_args = experiment_config.get("network_args", {})
 
@@ -51,22 +46,6 @@ def run_experiment(dataset, network, model, name, epoch, train_args):
 	# input_example = np.array([[1., 2.5, 3. , 1.7, 2.1, 1.3, .5, .75, .89, 1.9, 2.15, 2.2, .6]])
 	# mlflow.pyfunc.save_model(path="my_model", python_model=model, signature=signature, input_example=input_example )
 
-	# with mlflow.start_run():
-	# 	# mlflow.log_param("dataset", dataset)
-	# 	# mlflow.log_param("network", network)
-	# 	# mlflow.log_param("model", model)
-	
-	# 	model = model_class_(dataset_cls=dataset_class_, network_fn=network_fn)
-		
-	# 	# mlflow.keras.autolog()
-	# 	# model_ = train_model(
-	# 	# 	model,
-	# 	# 	dataset,
-	# 	# 	epochs=epoch,
-	# 	# 	# batch_size=experiment_config["train_args"]["batch_size"]
-	# 	# )
-	# 	mlflow.pyfunc.save_model(path="my_model", python_model=model )
-
 	config = dict(
 		dataset = dataset,
 		network = network,
@@ -74,31 +53,70 @@ def run_experiment(dataset, network, model, name, epoch, train_args):
 		epoch = epoch,
 		train_args = train_args
 	)
+
+	net_config = dict(
+			input_shape=(13,),
+			output_shape=(1),
+			layer_size=64,
+			dropout_amount=0.2,
+			num_layers=3
+		)
 	
-	with wandb.init(project=name, config=config):
+	with wandb.init(project=proj_name, config=config) as run:
 		config = wandb.config
-		model.fit(dataset=config.dataset, callbacks=[WandbCallback()])
+        
+		# Add model artifact
+		model_artifact = wandb.Artifact("convnet", type="model", description="Simple AlexNet style CNN", metadata=dict(net_config))        
+		model.network.save("initialized_model.keras")
+		model_artifact.new_file("initialized_model.keras")
+		wandb.save("initialized_model.keras")
+		run.log_artifact(model_artifact)
+
+
+		# Add data artifact
+		raw_data = wandb.Artifact(
+            "mnist-raw", type="dataset",
+            description="sklearn.datasets.load_boston",
+            metadata={"source": "keras.datasets.mnist",
+                      #"size (rows)": [model.dataset.X.shape[0]]
+					  })
+		with raw_data.new_file("raw" + ".npz", mode="wb") as file:
+			np.savez(file, x=model.data.X, y=model.data.y)
+		run.log_artifact(raw_data)
+
+
+		preprocessed_data = wandb.Artifact(
+            "mnist-processed", type="dataset",
+            description="sklearn.datasets.load_boston",
+            metadata={"source": "keras.datasets.mnist",
+                      #"size (rows)": [model.dataset.X.shape[0]]
+					  })
+		with preprocessed_data.new_file("training" + ".npz", mode="wb") as file:
+			np.savez(file, x=model.data.X_tr, y=model.data.y_tr)
+		run.log_artifact(preprocessed_data)
 
 
 
 
+		
+
+
+
+
+
+		model.fit(dataset=config.dataset, callbacks=[WandbCallback()])
+
+
 	# model_ = train_model(
 	# 		model,
 	# 		dataset,
 	# 		epoch
 	# 	)
-	# callbacks = []
-	# model.fit(dataset=dataset)
-
-
 
 
 
 
 if __name__ == "__main__":
-	# args = get_args()
-	# print(args["dataset"], args["network"], args["model"], args["epoch"], args["train_args"])
-	# run_experiment("HousingData", "mlp", "Model", 10, DEFAULT_TRAIN_ARGS )
 	run_experiment()
 	
 
diff --git a/nd_lang/lab1/training/util.py b/nd_lang/lab1/training/util.py
index 5f59b58..1d49796 100644
--- a/nd_lang/lab1/training/util.py
+++ b/nd_lang/lab1/training/util.py
@@ -1,6 +1,7 @@
 """ Function to train a model. """
 # from time import time
 
+import importlib
 from tensorflow.keras.callbacks import EarlyStopping
 from lab1.language_model.datasets.dataset import Dataset
 from lab1.language_model.models.base2 import Model
@@ -12,10 +13,19 @@ import wandb
 
 
 
-def save_net_artifact(project_name, network, config):
+def save_net_artifact(project_name, network):
 	"""
-	Neural Net used artifact. For model versioning
+	Save artifact of neural net used. For model versioning
 	"""
+	config = dict(
+			input_shape=(13,),
+			output_shape=(1),
+			layer_size=64,
+			dropout_amount=0.2,
+			num_layers=3
+		)
+
+
 	with wandb.init(project=project_name, job_type="initialize", config=config) as run:
 		config = wandb.config
 		
@@ -72,3 +82,9 @@ def train_model(model: Model,
 
 
 
+if __name__ == "__main__":
+	""" do something """
+	network = "mlp"
+	networks_module = importlib.import_module("lab1.language_model.networks.mlp")
+	network_fn = getattr(networks_module, network)
+	save_net_artifact("test-02", network_fn())
